import json
import pandas as pd
import requests
import subprocess

from csv import DictReader
from io import StringIO
from requests.structures import CaseInsensitiveDict


"""
for some reason I can't get the sample-metadata API client installed and working locally
this is a really rubbish workaround, and was probably a massive waste of time... 
it was easier than playing around with the same endpoints in Swagger though
"""


def get_auth() -> str:
    """
    uses a shell to execute the auth token grab
    :return: str: the token generated by the gcloud process

    This is of course a greasy hack, and will never translate to any other environments
    It does facilitate local playing with the metadata api, and that will broadly translate into other contexts
    """
    return subprocess.Popen(
        ['gcloud', 'auth', 'print-identity-token'],
        stdout=subprocess.PIPE,
        universal_newlines=True
    ).communicate()[0].rstrip()


def get_response(url, headers, query_params=None) -> requests.Response:
    """
    perform the actual execution of the URL with provided parameters
    :param url: str
    :param headers: dict
    :param query_params: [optional] dict
    :return: requests.Response
    """

    resp = requests.get(headers=headers, url=url, params=query_params)
    if resp.status_code != 200:
        raise Exception(f"non-200 status code for {url}, {headers}, {query_params}")

    return resp


# this is an update-able variable,
INTERESTING_FAMILIES = {"FAM000320", "FAM000327", "FAM000334", "FAM000337", "FAM000340"}

# here we will build a set of the participant IDs within these families, using the mapping endpoints
CHOSEN_INDIVIDUALS = set()
CHOSEN_INDIVIDUALS_PER_FAMILY = {}


URL_BASE = "https://sample-metadata-api-mnrpw3mdza-ts.a.run.app/api/v1"
ACCEPT_ALL = "*/*"
ACCEPT_JSON = "application/json"
FAMILY_ENDPOINT = "family"
PARTICIPANT_ENDPOINT = "participant"
SAMPLE_ENDPOINT = "sample"
PEDIGREE = "pedigree"

# subject to flexibility here
PROJECT = "acute-care"

# only get this once, for now
AUTH_TOKEN = get_auth()

table_header = CaseInsensitiveDict(
    data={
        "Accept": ACCEPT_ALL,
        "Authorization": f"Bearer {AUTH_TOKEN}"
    }
)

mapping_header = CaseInsensitiveDict(
    data={
        "Accept": ACCEPT_JSON,
        "Authorization": f"Bearer {AUTH_TOKEN}"
    }
)

# core query params from documentation
# get the pedigrees across the entire project
response = get_response(
    url=f"{URL_BASE}/{FAMILY_ENDPOINT}/{PROJECT}/{PEDIGREE}",
    headers=table_header,
    query_params={
        "replace_with_participant_external_ids": True,
        "replace_with_family_external_ids": True,
        "empty_participant_value": "",
        "include_header": True
    }
)

# parse this into a series of dictionaries, then into a dataframe
dict_read = DictReader(StringIO(response.content.decode().strip("#")), delimiter="\t")
df = pd.DataFrame([line for line in dict_read])

# -#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#- #
# so now we have a dataframe of the entire pedigree structure
# NOTE - this is just a hack around, with examples of further hackery

# # example queries on df - all affected females
# aff_females = df.loc[(df["Affected"] == "2") & (df["Sex"] == "2")]
#
# # all members of those families
# all_aff_female_families = df.loc[df["Family ID"].isin(aff_females["Family ID"].values)]
#
# # are there any affected parents? - affected and not "proband" in name (should be none in acute care)
# aff_parents = df.loc[
#   (df["Affected"] == "2") &
#   (~df["Individual ID"].str.contains("proband")),
#   ["Family ID", "Individual ID"]
# ]
# -#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#- #

# ok, here's an exploratory route
# choose a random ID, obtained by translating the incremented ID to external ID
selected_id = df.iloc[1]["Individual ID"]

# we can obtain a lookup on the internal sample ID using the external PID
# participant/acute-care/external-pid-to-internal-sample-id # JSON
# this will get us a CPG ID (INTernal, not INTeger)
response = get_response(url=f"{URL_BASE}/{PARTICIPANT_ENDPOINT}/{PROJECT}/external-pid-to-internal-sample-id", headers=mapping_header)
paired_samples_list = response.json()

## USEFUL MAPPING
pid_to_sample_id = dict(zip([_[0] for _ in paired_samples_list], [_[1] for _ in paired_samples_list]))

# we can then map the internal sample IDs to external sample IDs
# sample/acute-care/id-map/internal/all # JSON
response = get_response(url=f"{URL_BASE}/{SAMPLE_ENDPOINT}/{PROJECT}/id-map/internal/all", headers=mapping_header)

## USEFUL MAPPING
internal_to_ext_map = response.json()

# iterate over each family ID, getting the external sample IDs for each participant
for each_family in INTERESTING_FAMILIES:

    CHOSEN_INDIVIDUALS_PER_FAMILY[each_family] = []

    # isolate all rows containing the family members from the pedigree table
    members_df = df.loc[df["Family ID"] == each_family]
    original_ids = {row["Individual ID"] for index, row in members_df.iterrows()}

    # now translate those IDs to something usable
    for member_id in original_ids:
        # participant to sample
        int_sample_id = pid_to_sample_id.get(member_id)
        # internal sample to external sample
        ext_sample_id = internal_to_ext_map.get(int_sample_id)
        # store
        CHOSEN_INDIVIDUALS.add(int_sample_id)
        CHOSEN_INDIVIDUALS_PER_FAMILY[each_family].append(int_sample_id)

# this is the form we're taking for the trio extraction input
print(json.dumps(CHOSEN_INDIVIDUALS_PER_FAMILY, indent=4))

# # we could then get all details for those samples
# # sample/acute-care/<ext sample id>/details # JSON
# response = get_response(url=f"{URL_BASE}/{SAMPLE_ENDPOINT}/{PROJECT}/{ext_sample_id}/details", headers=mapping_header)
# print(response.json())
